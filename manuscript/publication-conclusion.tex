\section{Conclusion}

An LCA study, as formulated in Eq.~\ref{eqn:study}, can be published in a structured format by providing data users with sufficient information to unambiguously construct the foreground matrices $A_f$, $A_d$, and $B_f$, and also to clearly identify the meaning of the nonzero row and column entries in each matrix.  This can be accomplished by providing sparse, tabular data that make up the matrices, and an entity map which relates the rows and columns to references on the Web.  A study author can provide varying degrees of transparency in reporting their study, but the structured publication format ensures that a reader or data user can interpret the information in the way the author intended.  The entity map also serves as a formal statement of the functional scope of the study.

Before the goal of easily reproducible foreground models can be realized, the linked data foundation must be laid.   The four entity classes found in foreground studies, namely foreground flows, background processes, elementary flows, and characterization quantities, must shift from being recorded locally to being stored on the Semantic Web, where their shared meaning can be curated.  Fortunately, this is easy to do: authoritative sources simply need to publish hyperlinks to their content. Providers of aggregated inventory data should make available static hyperlinks to their content, so that licensees and data users can make shared reference to the same entities, even if the data may not be accessible to the general public. %Thinkstep already does this: every process inventory they publish has a stable link on the Web\footnote{\href{http://gabi-documentation-2016.gabi-software.com/xml-data/processes/f8dddbcb-f08c-4217-99de-0b59d2c11bb1.xml}{http://gabi-documentation-2016.gabi-software.com/xml-data/processes/[UUID].xml} where [UUID] is replaced with the process's unique identifier. For example, \texttt{f8dddbcb-f08c-4217-99de-0b59d2c11bb1} corresponds to production of 1,3-Butadiene, via catalytic dehydrogenation of butane, in Germany in 2015.}.
Similarly, impact assessment providers should publish their characterization data in a way that allows for automatic query and validation.  Both of these tasks can be accomplished independently through the efforts of members of the LCA community; however, the accuracy and validity of the data would be improved if the work were done by the data providers themselves.

Foreground studies are distinct from process inventory data sets, about which there is much ongoing work to establish file formats and standards.  To avoid the need for a similar enterprise for foreground publications, a minimal, inclusive standardization of information should be sought that makes the fewest possible prescriptions on its content.  The publication model presented here is meant to identify the minimal requirements that a study can be both reproduced and interpreted accurately: an \emph{entity map}, a list of references to entities used in the study; and \emph{tabular data} to fill in the model in Eq.~\ref{eqn:study}.  From such a simple prescription, a framework for distributed, platform-independent LCA computation can be imagined.
