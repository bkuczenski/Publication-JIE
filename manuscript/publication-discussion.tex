\section{Discussion}

An LCA foreground study can be published concisely by distinguishing foreground components from background components, explicitly identifying all entities involved in the study, and then reporting the data values that make up the submatrices in Eq.~\ref{eqn:study}.  As the examples demonstrate, a structured publication can be created that allows a reader to critically review, validate, and accurately reproduce the product system model without any additional information.  The entity map provides the foundation for a linked-data publication by explicitly naming all externally-referenced entities involved in the foreground model.  Ultimately it should be possible to name entities using linked data identifiers or URIs, allowing unambiguous, automatic retrieval of metadata about the entities.

The input matrices ($A_f$, $A_d$, and $B_f$) or aggregation results ($\tilde{\mathbf{x}}$, $\tilde{\mathbf{a}}_d$, $\tilde{\mathbf{b}}_f$), together with the entity map, form a research object that can be easily generated and shared with colleagues.  By separating foreground and background, the research object satisfies the objective for attribution, because only the information attributable to the study author is included in the research object; whereas information that came from the background database is excluded from the publication.

This framework allows an author a great deal of flexibility in publishing their model.  Any of the components or intermediate results visualized in Figure~\ref{fig:foreground} may be selected for publication at any level of detail.  By publishing a set of linked data identifiers corresponding to the rows and entries of the matrices, the author ensures that the data user will be able to identify the foreground and determine the background processes used. Again because the background is excluded, the size of the research object is kept down, and licensing limitations associated with the distribution of proprietary data are avoided. Use of the research object to selectively exclude private data is discussed in the supplementary materials.

\subsection{Validating LCIA Results}

As shown in Eq.~\ref{eqn:lci}, the LCIA results for a foreground system are the sum of the foreground and background scores.  The foreground scores are computed from the foreground emissions, while the background scores are computed from LCI results included in the background database.  These two components require distinct approaches for study validation.

For foreground scores, the LCIA results depend on the information provided in $B_f$ combined with the characterization factors for the LCIA methods selected.  Because LCIA methods are maintained independently from LCI databases and LCA software providers, the redundant implementation of these methods by different providers and/or software makers is a significant source of irreproducibility \citep{Speck_2015,Herrmann_2015}.  In the context of a structured publication, the most transparent approach is for the publication to include the characterization factors used in the study, which allows a reader to inspect them and check the results.  

For background scores, the results cannot be validated without access to the background database.  Again, the characterization factors used would need to be disclosed along with the background LCI results.  Because background databases are occasionally updated, it is important for a background dependency reference to include information about which version was used.  Assuming datasets within a particular background database do not change, it would be possible to create an archive of unit impact scores for each background process and LCIA method supported by the database.  These values could then be independently shared and validated.

In the context of structured publication, a reader of the publication could obtain the unit LCIA scores for each background dataset referenced, and use them to validate the background LCIA result. If the background database is subject to licensing restrictions, it may be necessary to require readers or data users to independently obtain background LCIA scores.  However, it may also be possible for the author to publish unit impact scores for background processes used in the model without violating licensing terms. In this case, it is much easier to reproduce published results, though the reader may still wish to check the author's published unit scores for accuracy.  If unit impact scores for background processes are included in the publication, then it is a simple matter for a reader to perform a contribution analysis and inspect the sensitivity of the results to foreground parameters.  This is exemplified in the ``organic potato'' publication provided in the supplementary materials.  

\subsection{Avoiding Redundancy in LCA Computation}

Considering the discussion of LCIA score reproducibility, it is evident that relying on study authors to individually perform flow characterization, background LCI computation, and background LCIA computation generates a tremendous duplication of effort in the LCA community.  Although background LCI and LCIA results are static as long as the background database is not revised, the conventional approach to LCA requires study authors to individually re-compute background inventory results and LCIA scores for every study.  This has weighty implications:

\begin{itemize}
\item If the database is provided in unit process form, then the practitioner must have access to the entire database in order to compute any LCI result.  This means that every licensee must download the full database upon purchasing a license.
\item Different LCA software providers must independently ensure that their software can support every LCI database their users may wish to use.  This %leads to redundancy of implementation at the inventory level, which
  causes redundancy and can introduce errors and inconsistencies.
\item Database updates become inconvenient, because every update requires a complete replacement of the database. This inhibits the deployment of incremental updates, even when errors are found.
\item Because of the increased burden of data updates, software providers may be slow to apply updates from LCI providers.  Additionally, it is more likely that users will postpone updating their software, leading to the possibility of version mismatches between users or software systems.
\item Software providers must also independently implement LCIA methods, which introduces the same possibilities of errors, inconsistencies, and version mismatches.
\end{itemize}

In contrast, a computational approach based on foreground study publication separates the concerns of study authorship from software and database maintenance.  In principle, the product system models presented as examples in this paper could remain unchanged even if background databases and LCIA methodologies were completely revised.  A study publication could be easily updated simply by changing which entities are pointed to by the entity map.  This exercise is well defined and easily reviewed.  It would also allow for a straightforward comparison of the changes to study results after a database update, a task that is currently challenging to perform.

A further implication of the linked data approach suggested here is a shift away from stand-alone computation of background data results, and toward a system where authoritative data providers compute aggregation and characterization results as a service for their users.  In such a system, data users would supply a query in the form of a particular reference to a background process or elementary flow, and service providers would answer the query with LCI results, LCIA results, or characterization factors.  Answers could be provided on-demand to study authors, readers, reviewers, or downstream data users.

This approach, which could be termed ``aggregation by reference'' and ``characterization by reference,'' could dramatically reduce the complexity of authoring LCA studies, in principle allowing authors to construct whole product system models without procuring any data.  Before computation of results could be performed, authors would have to obtain access to the desired datasets.  It would also situate the data providers as the sole authoritative sources for results derived from their data.  This has the dual effects of giving readers increased confidence in the correctness of the results, and in ensuring that the data providers continue to occupy an indispensible role in study preparation and review.

Finally, it would allow data providers to directly control access to their intellectual property.  A given query for an aggregation result could be answered in different ways depending on the credentials of the user making the query, and depending on the context of the query.  For example, an authorized critical reviewer of a published study may be given free access to the requested dataset, whereas a member of the general public would be given only the impact score.

%%%% TODO TODO TODO TODO!!!!!!! save it for the revision
\subsection{Interlinking Foreground Models}

Current practice does not provide a way for study authors to easily provide their models to collaborators, or for  independently created models to be linked together.  However, structured publication of foreground studies could allow independent authors to work together on complex models.  Large foregrounds can be easily partitioned into fragments simply by selectively including or excluding columns of $A_f$, $A_d$, and $B_f$ in different publications, allowing for independent maintenance of different subsystems. Similarly, an isolated product system described in a structured format could easily be combined with other models of complementary systems to form a larger system.  Independent foreground systems that both reference the same shared cutoff flows could be automatically linked without any intervention by the authors.

In both cases, the interlinking of foreground models rests on the principle of shared reference to common entities.  Linked semantic data provides an enabling technology, both allowing standalone foreground publications to be automatically linked to data resources and to one another, and by providing interpretive services such as dataset discovery, flow matching, unit conversion, and metadata retrieval.  This represents an opportunity for further research and development.


\endinput


%% First, the reimplementation introduces the possibility for errors and discrepancies.  Second, the labor of revising and updating characterization factors is multiplied because every implementation must be updated separately.  Third, different implementations may be out of sync with each other.  Finally, the reimplementations may themselves not be easily reviewed when studies using them are reviewed.




If a publication includes LCIA results, then a reader with access to the same background database used by the author can validate the scores by computing the unit impact scores for background datasets referenced in the publication.  It may also be possible for the author to publish unit impact scores for background processes without violating licensing terms, in which case the reader can check the scores for accuracy.


By selecting which input matrices , $\tilde{\mathbf{b}}_x$, or $\tilde{\mathbf{b}}$, as well as the LCIA result $\tilde{s}$) are published, the author can determine the level of transparency of the publication.  By reporting the matrices or vectors in sparse form as delimited files, the author can enable a data user to easily reconstruct the model, and if applicable, reproduce the result.








\endinput

Points to cover here:

* attribution-- foreground contains only data attributable to study author
* isolation of background-- presents opportunities to background data providers (licensing / agg on demand)
* characterization section can stay

* handling allocation?

- need to re-read after examples are done

The publication then becomes the authoritative statement of that assertion.

Particularly in LCA, licensing restrictions may prohibit the inclusion of data from background databases in a study.

A research object must contain all the information necessary to accomplish its goal.  However, the object must also be of manageable size and should exclude information that is not required or that can be found elsewhere.

The separation of foreground elements from the background database(s) achieves the attribution objective because it distinguishes the study author's contribution from data from other sources.

This model is not useful for publishing background systems (i.e. where the background depends on the output of the product system being modeled)

